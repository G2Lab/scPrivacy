{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import qtl.norm\n",
    "import itertools as it\n",
    "import numba as nb\n",
    "\n",
    "from os import makedirs, path\n",
    "from typing import Union, List\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADPBulk from https://github.com/noamteyssier/adpbulk/blob/main/adpbulk/adpbulk.py\n",
    "\n",
    "class ADPBulk:\n",
    "    def __init__(\n",
    "            self,\n",
    "            adat: anndata.AnnData,\n",
    "            groupby: Union[List[str], str],\n",
    "            method: str = \"sum\",\n",
    "            name_delim: str = \"-\",\n",
    "            group_delim: str = \".\",\n",
    "            use_raw: bool = False):\n",
    "        \"\"\"\n",
    "        Class of Pseudo-Bulking `AnnData` objects based on categorical variables\n",
    "        found in the `.obs` attribute\n",
    "        inputs:\n",
    "            adat: anndata.AnnData\n",
    "                The `AnnData` object to process\n",
    "            groupby: Union[List[str], str]\n",
    "                The categories to group by. Can provide as a single value\n",
    "                or a list of values.\n",
    "            method: str\n",
    "                The method to aggregate with (sum[default], mean, median)\n",
    "            name_delim: str\n",
    "                The delimiter to use when grouping multiple categories together.\n",
    "                example: 'cat1{delim}cat2'\n",
    "            group_delim: str\n",
    "                The delimiter to use for adding the value to its category.\n",
    "                example: 'cat{delim}value'\n",
    "            use_raw: bool\n",
    "                Whether to use the `.raw` attribute on the `AnnData` object\n",
    "        \"\"\"\n",
    "\n",
    "        self.agg_methods = {\n",
    "            \"sum\": np.sum,\n",
    "            \"mean\": np.mean,\n",
    "            \"median\": np.median}\n",
    "\n",
    "        self.adat = adat\n",
    "        self.groupby = groupby\n",
    "        self.method = method\n",
    "        self.name_delim = name_delim\n",
    "        self.group_delim = group_delim\n",
    "        self.use_raw = use_raw\n",
    "\n",
    "        self.group_idx = dict()\n",
    "        self.groupings = list()\n",
    "        self.grouping_masks = dict()\n",
    "\n",
    "        self.meta = pd.DataFrame([])\n",
    "        self.matrix = pd.DataFrame([])\n",
    "        self.samples = pd.DataFrame([])\n",
    "\n",
    "        self._isfit = False\n",
    "        self._istransform = False\n",
    "\n",
    "        self._validate()\n",
    "\n",
    "    def _validate(self):\n",
    "        \"\"\"\n",
    "        validates that the input is as expected\n",
    "        \"\"\"\n",
    "        self._validate_anndata()\n",
    "        self._validate_groups()\n",
    "        self._validate_method()\n",
    "        self._validate_raw()\n",
    "\n",
    "    def _validate_anndata(self):\n",
    "        \"\"\"\n",
    "        validates that the anndata object is as expected\n",
    "        \"\"\"\n",
    "        if self.adat.X is None:\n",
    "            raise AttributeError(\"Provided Matrix is None\")\n",
    "        if self.adat.obs is None:\n",
    "            raise AttributeError(\"Provided Obs are None\")\n",
    "        if self.adat.var is None:\n",
    "            raise AttributeError(\"Provided Var are None\")\n",
    "\n",
    "    def _validate_groups(self):\n",
    "        \"\"\"\n",
    "        validates that the groups are as expected\n",
    "        \"\"\"\n",
    "        # convert groups to list if provided as str\n",
    "        if isinstance(self.groupby, str):\n",
    "            self.groupby = [self.groupby]\n",
    "\n",
    "        if isinstance(self.groupby, list):\n",
    "            self.groupby = np.unique(self.groupby)\n",
    "            for group in self.groupby:\n",
    "                self._validate_group(group)\n",
    "        else:\n",
    "            raise TypeError(\"Groupby is not a list or str\")\n",
    "\n",
    "    def _validate_group(self, group):\n",
    "        \"\"\"\n",
    "        confirms that provided group is a column in the observations\n",
    "        \"\"\"\n",
    "        if group not in self.adat.obs.columns:\n",
    "            raise ValueError(f\"Provided group {group} not in observations\")\n",
    "\n",
    "    def _validate_method(self):\n",
    "        \"\"\"\n",
    "        confirms that the method is known\n",
    "        \"\"\"\n",
    "        if self.method not in self.agg_methods.keys():\n",
    "            raise ValueError(\n",
    "                f\"Provided method {self.method} not in known methods {''.join(self.agg_methods)}\")\n",
    "\n",
    "    def _validate_raw(self):\n",
    "        \"\"\"\n",
    "        if the `use_raw` flag is provided will confirm that\n",
    "        the raw field is present\n",
    "        \"\"\"\n",
    "        if self.use_raw and self.adat.raw is None:\n",
    "            raise AttributeError(\n",
    "                \"use_raw provided, but no raw field is found in AnnData\")\n",
    "\n",
    "\n",
    "    def _fit_indices(self):\n",
    "        \"\"\"\n",
    "        determines the indices for each of the provided groups\n",
    "        \"\"\"\n",
    "        for group in self.groupby:\n",
    "            unique_values = np.unique(self.adat.obs[group].values)\n",
    "            self.group_idx[group] = {\n",
    "                uv: set(np.flatnonzero(self.adat.obs[group].values == uv))\n",
    "                    for uv in tqdm(unique_values, desc=f\"fitting indices: {group}\")}\n",
    "\n",
    "    def _get_mask(self, pairs: tuple) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        retrieve the indices for the provided values from their respective groups\n",
    "        calculates the global intersection between the sets\n",
    "        \"\"\"\n",
    "        group_indices = []\n",
    "        for j, key in enumerate(pairs):\n",
    "            group_indices.append(self.group_idx[self.groupby[j]][key])\n",
    "        mask = set.intersection(*group_indices)\n",
    "        return np.array(list(mask))\n",
    "\n",
    "    def _get_name(self, pairs: tuple) -> str:\n",
    "        \"\"\"\n",
    "        create a name for the provided values based on their respective groups\n",
    "        \"\"\"\n",
    "        name = self.name_delim.join([\n",
    "                f\"{self.groupby[i]}{self.group_delim}{pairs[i]}\" for i in range(len(pairs))])\n",
    "        return name\n",
    "\n",
    "    def _get_agg(self, mask: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        runs the aggregation function with the provided sample mask\n",
    "        \"\"\"\n",
    "        if self.use_raw:\n",
    "            mat = self.adat.raw.X[mask]\n",
    "        else:\n",
    "            mat = self.adat.X[mask]\n",
    "        return self.agg_methods[self.method](mat, axis=0)\n",
    "\n",
    "    def _get_var(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        return the var names using the given scheme (normal/raw)\n",
    "        \"\"\"\n",
    "        if self.use_raw:\n",
    "            return self.adat.raw.var.index.values\n",
    "        else:\n",
    "            return self.adat.var.index.values\n",
    "\n",
    "    def _prepare_meta(self, pairs: tuple) -> dict:\n",
    "        \"\"\"\n",
    "        defines the meta values for the pairs\n",
    "        \"\"\"\n",
    "        values = {\n",
    "            self.groupby[idx]: pairs[idx] for idx in np.arange(len(self.groupby))\n",
    "            }\n",
    "        values[\"SampleName\"] = self._get_name(pairs)\n",
    "        return values\n",
    "\n",
    "    def _build_groupings(self):\n",
    "        \"\"\"\n",
    "        generate the grouping iterable\n",
    "        \"\"\"\n",
    "        if len(self.groupby) > 1:\n",
    "            group_keys = [self.group_idx[g].keys() for g in self.groupby]\n",
    "            self.groupings = list(it.product(*group_keys))\n",
    "        else:\n",
    "            self.groupings = self.group_idx[self.groupby[0]]\n",
    "\n",
    "    def _build_masks(self):\n",
    "        \"\"\"\n",
    "        generate the masks for each of the groupings and generates the\n",
    "        metadata for each of the groupings\n",
    "        \"\"\"\n",
    "        self.grouping_masks = dict()\n",
    "        self.meta = []\n",
    "        for pairs in self.groupings:\n",
    "            if not isinstance(pairs, tuple):\n",
    "                pairs = tuple([pairs])\n",
    "            mask = self._get_mask(pairs)\n",
    "            if mask.size > 0:\n",
    "                self.grouping_masks[pairs] = mask\n",
    "                self.meta.append(self._prepare_meta(pairs))\n",
    "\n",
    "        if len(self.meta) == 0:\n",
    "            raise ValueError(\"No combinations of the provided groupings found\")\n",
    "        self.meta = pd.DataFrame(self.meta)\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        fits the indices for each of the groups\n",
    "        \"\"\"\n",
    "        self._fit_indices()\n",
    "        self._build_groupings()\n",
    "        self._build_masks()\n",
    "        self._isfit = True\n",
    "\n",
    "    def transform(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        performs the aggregation based on the fit indices\n",
    "        \"\"\"\n",
    "        if not self._isfit:\n",
    "            raise AttributeError(\"Please fit the object first\")\n",
    "\n",
    "        matrix = []\n",
    "        for pairs in tqdm(self.groupings, desc=\"Aggregating Samples\"):\n",
    "            if not isinstance(pairs, tuple):\n",
    "                pairs = tuple([pairs])\n",
    "            if pairs in self.grouping_masks:\n",
    "                matrix.append(self._get_agg(self.grouping_masks[pairs]))\n",
    "        \n",
    "        # stack all observations into single matrix\n",
    "        matrix = np.vstack(matrix)\n",
    "\n",
    "        self.matrix = pd.DataFrame(\n",
    "            matrix,\n",
    "            index=self.meta.SampleName.values,\n",
    "            columns=self._get_var())\n",
    "\n",
    "        self._istransform = True\n",
    "        return self.matrix\n",
    "\n",
    "    def fit_transform(self):\n",
    "        \"\"\"\n",
    "        firs the indices and performs the aggregation based on those indices\n",
    "        \"\"\"\n",
    "        self.fit()\n",
    "        return self.transform()\n",
    "\n",
    "    def get_meta(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        return the meta dataframe\n",
    "        \"\"\"\n",
    "        if not self._isfit:\n",
    "            raise AttributeError(\"Please fit the object first\")\n",
    "        return self.meta\n",
    "\n",
    "\n",
    "def get_pca_linear_model_residuals(normalized_matrix):\n",
    "    # scale data prior to PCA\n",
    "    scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "    scaled_normalized_matrix = scaler.fit_transform(normalized_matrix)\n",
    "    \n",
    "    # fit PCA\n",
    "    pca = PCA(n_components=10)\n",
    "    pca_features = pca.fit_transform(scaled_normalized_matrix)\n",
    "    \n",
    "    # fit linear model\n",
    "    reg = LinearRegression().fit(pca_features, normalized_matrix)\n",
    "    predicted_vals = reg.predict(pca_features)\n",
    "\n",
    "    # get residuals for log-TMM-normalized cell-type-specific pseudobulk\n",
    "    model_residuals = normalized_matrix - predicted_vals\n",
    "\n",
    "    # return transpose\n",
    "    return model_residuals.T\n",
    "\n",
    "\n",
    "def create_ct_df(in_df, cell_type, samples):\n",
    "    ct_dic = {}\n",
    "    df_cols = list(in_df)\n",
    "\n",
    "    for s in samples:\n",
    "        sample_col = f\"cell_type_name.{cell_type}-donor_id.{s}\"\n",
    "        if sample_col in df_cols:\n",
    "            ct_dic[s] = np.asarray(in_df[sample_col])\n",
    "        else:\n",
    "            ct_dic[s] = np.zeros(len(in_df))\n",
    "            ct_dic[s][:] = np.nan\n",
    "\n",
    "    ct_df = pd.DataFrame(ct_dic)\n",
    "    ct_df.index = in_df.index\n",
    "    return ct_df\n",
    "\n",
    "\n",
    "\n",
    "def lupus_create_ct_df(in_df, cell_type, samples):\n",
    "    ct_dic = {}\n",
    "    df_cols = list(in_df)\n",
    "\n",
    "    for s in samples:\n",
    "        sample_col = f\"ind_cov.{s}-onek1k_cell_type.{cell_type}\"\n",
    "        if sample_col in df_cols:\n",
    "            ct_dic[s] = np.asarray(in_df[sample_col])\n",
    "        else:\n",
    "            ct_dic[s] = np.zeros(len(in_df))\n",
    "            ct_dic[s][:] = np.nan\n",
    "\n",
    "    ct_df = pd.DataFrame(ct_dic)\n",
    "    ct_df.index = in_df.index\n",
    "    return ct_df\n",
    "\n",
    "\n",
    "# @nb.njit(parallel=True)\n",
    "# def jit_inverse_normal_transform(M):\n",
    "#     n_rows, n_cols = M.shape\n",
    "#     Q = np.empty_like(M)\n",
    "#     for i in nb.prange(n_rows):\n",
    "#         R = np.argsort(np.argsort(M[i])) + 1\n",
    "#         Q[i] = stats.norm.ppf(R / (n_cols + 1))\n",
    "#     return Q\n",
    "\n",
    "# def inverse_normal_transform_df(M_df):\n",
    "#     M_array = M_df.to_numpy()  # Convert DataFrame to NumPy array\n",
    "#     Q_array = jit_inverse_normal_transform(M_array)\n",
    "#     return pd.DataFrame(Q_array, index=M_df.index, columns=M_df.columns)\n",
    "\n",
    "\n",
    "def inverse_normal_transform(M):\n",
    "    \"\"\"Transform rows to a standard normal distribution\"\"\"\n",
    "    R = stats.rankdata(M, axis=1)  # ties are averaged\n",
    "    Q = stats.norm.ppf(R/(M.shape[1]+1))\n",
    "    Q = pd.DataFrame(Q, index=M.index, columns=M.columns)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input and output\n",
    "base_dir = \"/gpfs/commons/groups/gursoy_lab/cwalker/projects/sc_privacy/ml/\"\n",
    "data_dir = path.join(base_dir, \"data\")\n",
    "cell_by_gene_h5_dir = path.join(data_dir, \"onek1k\", \"cellbygene\")\n",
    "orig_cell_by_gene_h5_dir = path.join(data_dir, \"onek1k\", \"adata\")\n",
    "\n",
    "cell_by_gene_h5_fi = path.join(cell_by_gene_h5_dir, \"onek1k_cell_by_gene.h5ad\")\n",
    "orig_cell_by_gene_h5_fi = path.join(orig_cell_by_gene_h5_dir, \"local.h5ad\")\n",
    "\n",
    "# output meta\n",
    "out_metadata_dir = \"../data/metadata/onek1k\"\n",
    "makedirs(out_metadata_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.read_h5ad(cell_by_gene_h5_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_adata = anndata.read_h5ad(orig_cell_by_gene_h5_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ct in list(set(orig_adata.obs[\"cell_type\"])):\n",
    "    orig_df = orig_adata.obs[orig_adata.obs[\"cell_type\"] == ct].head(1)\n",
    "    orig_cell_type = orig_df[\"cell_type\"].item()\n",
    "    orig_index = orig_df.index.item()\n",
    "    new_name = adata.obs.loc[orig_index][\"new_names\"]\n",
    "\n",
    "    print(f\"{orig_cell_type}\\t{new_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct = \"naive thymus-derived CD8-positive, alpha-beta T cell\"\n",
    "# orig_df = orig_adata.obs[orig_adata.obs[\"cell_type\"] == ct]\n",
    "\n",
    "row_keys = orig_adata.obs.index\n",
    "filtered_row_keys = [key for key in row_keys if key in adata.obs.index]\n",
    "\n",
    "# adata.loc[filtered_row_keys]\n",
    "filtered_adata = adata[filtered_row_keys, :]\n",
    "filtered_orig_adata = orig_adata[filtered_adata.obs.index, :]\n",
    "\n",
    "assert filtered_adata.obs.index.equals(filtered_orig_adata.obs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ipykernel_32271/2047994924.py:1: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  filtered_orig_adata.obs[\"cell_type_name\"] = filtered_adata.obs[\"new_names\"]\n"
     ]
    }
   ],
   "source": [
    "filtered_orig_adata.obs[\"cell_type_name\"] = filtered_adata.obs[\"new_names\"]\n",
    "\n",
    "# filtered_orig_adata.obs.assign(cell_type_name=filtered_adata.obs.new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata = filtered_orig_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors = list(set(adata.obs[\"donor_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retained_ensembl_ids = list(adata.var.index)\n",
    "retained_gene_ids = list(adata.var[\"feature_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_id_out = path.join(out_metadata_dir, \"unfiltered_retained_ensembl_ids.txt\")\n",
    "gene_id_out = path.join(out_metadata_dir, \"unfiltered_retained_gene_ids.txt\")\n",
    "\n",
    "with open(ensembl_id_out, \"w\") as f:\n",
    "    f.write(\"\\n\".join(retained_ensembl_ids))\n",
    "\n",
    "with open(gene_id_out, \"w\") as f:\n",
    "    f.write(\"\\n\".join(retained_gene_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.raw = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_cell_types = list(set(adata.obs[\"cell_type_name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fitting indices: cell_type_name: 100%|██████████| 16/16 [00:00<00:00, 16.20it/s]\n",
      "fitting indices: donor_id: 100%|██████████| 981/981 [00:01<00:00, 760.21it/s]\n",
      "Aggregating Samples: 100%|██████████| 15696/15696 [00:29<00:00, 534.00it/s] \n"
     ]
    }
   ],
   "source": [
    "adpb = ADPBulk(adata, [\"donor_id\", \"cell_type_name\"], use_raw=True, method=\"mean\")\n",
    "pseudobulk_matrix = adpb.fit_transform()\n",
    "\n",
    "pseudobulk_matrix = pseudobulk_matrix.T\n",
    "gene_names = adata.var.feature_name\n",
    "pseudobulk_matrix.index = gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platelets 761\n",
      "Erythrocytes 210\n",
      "CD4_NC 981\n",
      "NK 981\n",
      "B_MEM 981\n",
      "NK_R 969\n",
      "CD8_S100B 980\n",
      "CD4_SOX4 855\n",
      "CD4_ET 981\n",
      "CD8_ET 981\n",
      "Mono_NC 926\n",
      "Mono_C 966\n",
      "Plasma 791\n",
      "B_IN 981\n",
      "CD8_NC 981\n",
      "DC 968\n"
     ]
    }
   ],
   "source": [
    "for cell_type in reduced_cell_types:\n",
    "    cell_type_cols = [col for col in pseudobulk_matrix if col.startswith(f\"cell_type_name.{cell_type}-\")]\n",
    "    cell_type_pseudobulk_matrix = pseudobulk_matrix[cell_type_cols]\n",
    "    print(cell_type, cell_type_pseudobulk_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sumagg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [1:06:43<00:00, 250.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# normalize pseudobulk gene counts by cell type and store in sample-specific dictionaries\n",
    "# pseudobulk_matrix = pseudobulk_matrix.T\n",
    "\n",
    "# dics for tmm-transformed data\n",
    "gene_pseudobulk_dics = {}\n",
    "gene_pseudobulk_invnorm_dics = {}\n",
    "# for sample in donors:\n",
    "#     gene_pseudobulk_dics[sample] = {}\n",
    "\n",
    "gene_pseudobulk_residuals_dics = {}\n",
    "# for sample in donors:\n",
    "#     gene_pseudobulk_residuals_dics[sample] = {}\n",
    "# # note the dic below is for tmm-transformed data with the RESIDUALS inv-norm\n",
    "# # transformed\n",
    "gene_pseudobulk_residuals_invnorm_transformed_dics = {}\n",
    "# for ct in donors:\n",
    "#     gene_pseudobulk_residuals_invnorm_transformed_dics[sample] = {}\n",
    "\n",
    "for cell_type in tqdm(reduced_cell_types):\n",
    "    # define cells\n",
    "    cell_type_cols = [col for col in pseudobulk_matrix if col.startswith(f\"cell_type_name.{cell_type}-\")]\n",
    "    # subset to keep only cells of cell type\n",
    "    cell_type_pseudobulk_matrix = pseudobulk_matrix[cell_type_cols]\n",
    "    # create log+1 pseudobulk matrix (sumagg)\n",
    "    log_pseudobulk_matrix = np.log2(cell_type_pseudobulk_matrix + 1)\n",
    "    # inverse normal transform the log pseudobulk matrix\n",
    "    inv_norm_log_pseudobulk_matrix = qtl.norm.inverse_normal_transform(log_pseudobulk_matrix)\n",
    "    # get residual expression using RINT-log pseudobulk matrix\n",
    "    log_model_residuals = get_pca_linear_model_residuals(log_pseudobulk_matrix.T)\n",
    "    # RINT the model residuals\n",
    "    inv_norm_transformed_log_model_residuals = qtl.norm.inverse_normal_transform(log_model_residuals)\n",
    "    # define matrices to store log pseudobulk, RINT-log-pseudobulk, and RINT-log-residual-pseudobulk\n",
    "    df_columns = list(log_pseudobulk_matrix)\n",
    "    log_pseudobulk_matrix_df = create_ct_df(\n",
    "        log_pseudobulk_matrix,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    inv_norm_transformed_log_pseudobulk_matrix_df = create_ct_df(\n",
    "        inv_norm_log_pseudobulk_matrix,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    inv_norm_transformed_log_pseudobulk_model_residuals_df = create_ct_df(\n",
    "        inv_norm_transformed_log_model_residuals,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    # assign processed cell-type data to dictionaries\n",
    "    gene_pseudobulk_dics[cell_type] = log_pseudobulk_matrix_df\n",
    "    gene_pseudobulk_invnorm_dics[cell_type] = inv_norm_transformed_log_pseudobulk_matrix_df\n",
    "    gene_pseudobulk_residuals_invnorm_transformed_dics[cell_type] = inv_norm_transformed_log_pseudobulk_model_residuals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cell_type_log_pseudobulk_dir = \"../data/onek1k_cell_type_pseudobulk/sum_agg/log_pseudobulk_matrices\"\n",
    "makedirs(out_cell_type_log_pseudobulk_dir, exist_ok=True)\n",
    "\n",
    "out_cell_type_inv_norm_log_pseudobulk_dir = \"../data/onek1k_cell_type_pseudobulk/sum_agg/invnorm_log_pseudobulk_matrices\"\n",
    "makedirs(out_cell_type_inv_norm_log_pseudobulk_dir, exist_ok=True)\n",
    "\n",
    "out_cell_type_inv_norm_log_pseudobulk_residuals_dir = \"../data/onek1k_cell_type_pseudobulk/sum_agg/invnorm_regression_residuals\"\n",
    "makedirs(out_cell_type_inv_norm_log_pseudobulk_residuals_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for ct in reduced_cell_types:\n",
    "    # process log tmm normalized\n",
    "    gene_pseudobulk_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_log_pseudobulk_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n",
    "\n",
    "    gene_pseudobulk_invnorm_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_inv_norm_log_pseudobulk_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n",
    "\n",
    "    gene_pseudobulk_residuals_invnorm_transformed_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_inv_norm_log_pseudobulk_residuals_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create log TMM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize pseudobulk gene counts by cell type and store in sample-specific dictionaries\n",
    "# pseudobulk_matrix = pseudobulk_matrix.T\n",
    "\n",
    "# dics for tmm-transformed data\n",
    "gene_pseudobulk_dics = {}\n",
    "gene_pseudobulk_invnorm_dics = {}\n",
    "# for sample in donors:\n",
    "#     gene_pseudobulk_dics[sample] = {}\n",
    "\n",
    "gene_pseudobulk_residuals_dics = {}\n",
    "# for sample in donors:\n",
    "#     gene_pseudobulk_residuals_dics[sample] = {}\n",
    "# # note the dic below is for tmm-transformed data with the RESIDUALS inv-norm\n",
    "# # transformed\n",
    "gene_pseudobulk_residuals_invnorm_transformed_dics = {}\n",
    "# for ct in donors:\n",
    "#     gene_pseudobulk_residuals_invnorm_transformed_dics[sample] = {}\n",
    "\n",
    "for cell_type in tqdm(reduced_cell_types):\n",
    "    # define cells\n",
    "    cell_type_cols = [col for col in pseudobulk_matrix if col.startswith(f\"cell_type_name.{cell_type}-\")]\n",
    "    # subset to keep only cells of cell type\n",
    "    cell_type_pseudobulk_matrix = pseudobulk_matrix[cell_type_cols]\n",
    "    # create TMM matrix\n",
    "    normalized_matrix = qtl.norm.edger_cpm(cell_type_pseudobulk_matrix, normalized_lib_sizes=True)\n",
    "    # create log+1 pseudobulk matrix (sumagg)\n",
    "    log_pseudobulk_matrix = np.log2(normalized_matrix + 1)\n",
    "    # inverse normal transform the log pseudobulk matrix\n",
    "    inv_norm_log_pseudobulk_matrix = qtl.norm.inverse_normal_transform(log_pseudobulk_matrix)\n",
    "    # get residual expression using RINT-log pseudobulk matrix\n",
    "    log_model_residuals = get_pca_linear_model_residuals(log_pseudobulk_matrix.T)\n",
    "    # RINT the model residuals\n",
    "    inv_norm_transformed_log_model_residuals = qtl.norm.inverse_normal_transform(log_model_residuals)\n",
    "    # define matrices to store log pseudobulk, RINT-log-pseudobulk, and RINT-log-residual-pseudobulk\n",
    "    df_columns = list(log_pseudobulk_matrix)\n",
    "    log_pseudobulk_matrix_df = create_ct_df(\n",
    "        log_pseudobulk_matrix,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    inv_norm_transformed_log_pseudobulk_matrix_df = create_ct_df(\n",
    "        inv_norm_log_pseudobulk_matrix,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    inv_norm_transformed_log_pseudobulk_model_residuals_df = create_ct_df(\n",
    "        inv_norm_transformed_log_model_residuals,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    # assign processed cell-type data to dictionaries\n",
    "    gene_pseudobulk_dics[cell_type] = log_pseudobulk_matrix_df\n",
    "    gene_pseudobulk_invnorm_dics[cell_type] = inv_norm_transformed_log_pseudobulk_matrix_df\n",
    "    gene_pseudobulk_residuals_invnorm_transformed_dics[cell_type] = inv_norm_transformed_log_pseudobulk_model_residuals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cell_type_log_pseudobulk_dir = \"../data/onek1k_cell_type_pseudobulk/log_tmm/log_pseudobulk_matrices\"\n",
    "makedirs(out_cell_type_log_pseudobulk_dir, exist_ok=True)\n",
    "\n",
    "out_cell_type_inv_norm_log_pseudobulk_dir = \"../data/onek1k_cell_type_pseudobulk/log_tmm/invnorm_log_pseudobulk_matrices\"\n",
    "makedirs(out_cell_type_inv_norm_log_pseudobulk_dir, exist_ok=True)\n",
    "\n",
    "out_cell_type_inv_norm_log_pseudobulk_residuals_dir = \"../data/onek1k_cell_type_pseudobulk/log_tmm/invnorm_regression_residuals\"\n",
    "makedirs(out_cell_type_inv_norm_log_pseudobulk_residuals_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for ct in reduced_cell_types:\n",
    "    # process log tmm normalized\n",
    "    gene_pseudobulk_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_log_pseudobulk_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n",
    "\n",
    "    gene_pseudobulk_invnorm_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_inv_norm_log_pseudobulk_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n",
    "\n",
    "    gene_pseudobulk_residuals_invnorm_transformed_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_inv_norm_log_pseudobulk_residuals_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lupus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus_integrated_h5 = \"/gpfs/commons/groups/gursoy_lab/xli/Lupus/integration/data/Lupus_corrected_integrated.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus_adata = sc.read_h5ad(lupus_integrated_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus_adata.raw = lupus_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_metadata_dir = \"../data/onek1k_variant_selection/metadata/lupus\"\n",
    "makedirs(out_metadata_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract lupus samples' auxiliary information and save to disk\n",
    "columns_to_extract = {\n",
    "    \"age_sex_pop\": ['ind_cov', 'Age', 'Sex', 'pop_cov'],\n",
    "    \"age_sex\": ['ind_cov', 'Age', 'Sex'],\n",
    "    \"age_pop\": ['ind_cov', 'Age', 'pop_cov'],\n",
    "    \"sex_pop\": ['ind_cov', 'Sex', 'pop_cov'],\n",
    "    \"age\": ['ind_cov', 'Age'],\n",
    "    \"sex\": ['ind_cov', 'Sex'],\n",
    "    \"pop\": ['ind_cov', 'pop_cov']\n",
    "}\n",
    "for col_set_name, cols in columns_to_extract.items():\n",
    "    selected_data = lupus_adata.obs[cols]\n",
    "    lupus_covariate_df = pd.DataFrame(selected_data)\n",
    "    lupus_covariate_df.rename(\n",
    "        columns={\n",
    "            'ind_cov': 'sample', 'Age': 'age', 'Sex': 'sex', 'pop_cov': 'pop'\n",
    "        },\n",
    "    inplace=True\n",
    "    )\n",
    "\n",
    "    lupus_covariate_df = lupus_covariate_df.drop_duplicates(subset=['sample'])\n",
    "    aux_out_path = path.join(out_metadata_dir, f\"auxiliary_{col_set_name}.tsv\")\n",
    "    lupus_covariate_df.to_csv(aux_out_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CZI lupus adata\n",
    "lupus_adata_file = \"/gpfs/commons/groups/gursoy_lab/cwalker/projects/sc_privacy/data/lupus/adata_2/fd5e58b5-ddff-457f-b182-d18f99e36207.h5ad\"\n",
    "czi_lupus_adata = anndata.read_h5ad(lupus_adata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors = list(set(czi_lupus_adata.obs[\"ind_cov\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lupus_adata.obs.index = lupus_adata.obs.index.str.rstrip('-lupus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(lupus_adata.obs.index == czi_lupus_adata.obs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "czi_lupus_adata.obs[\"onek1k_cell_type\"] = lupus_adata.obs[\"new_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_is_filtered</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>feature_reference</th>\n",
       "      <th>feature_biotype</th>\n",
       "      <th>feature_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000243485</th>\n",
       "      <td>True</td>\n",
       "      <td>MIR1302-2HG</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>gene</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000237613</th>\n",
       "      <td>True</td>\n",
       "      <td>FAM138A</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>gene</td>\n",
       "      <td>1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000186092</th>\n",
       "      <td>True</td>\n",
       "      <td>OR4F5</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>gene</td>\n",
       "      <td>2618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000238009</th>\n",
       "      <td>True</td>\n",
       "      <td>RP11-34P13.7</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>gene</td>\n",
       "      <td>3726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000239945</th>\n",
       "      <td>True</td>\n",
       "      <td>RP11-34P13.8</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>gene</td>\n",
       "      <td>1319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000212907</th>\n",
       "      <td>True</td>\n",
       "      <td>MT-ND4L</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>gene</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198886</th>\n",
       "      <td>True</td>\n",
       "      <td>MT-ND4</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>gene</td>\n",
       "      <td>1378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198786</th>\n",
       "      <td>True</td>\n",
       "      <td>MT-ND5</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>gene</td>\n",
       "      <td>1812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198695</th>\n",
       "      <td>False</td>\n",
       "      <td>MT-ND6</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>gene</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198727</th>\n",
       "      <td>True</td>\n",
       "      <td>MT-CYB</td>\n",
       "      <td>NCBITaxon:9606</td>\n",
       "      <td>gene</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30933 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature_is_filtered  feature_name feature_reference  \\\n",
       "ENSG00000243485                 True   MIR1302-2HG    NCBITaxon:9606   \n",
       "ENSG00000237613                 True       FAM138A    NCBITaxon:9606   \n",
       "ENSG00000186092                 True         OR4F5    NCBITaxon:9606   \n",
       "ENSG00000238009                 True  RP11-34P13.7    NCBITaxon:9606   \n",
       "ENSG00000239945                 True  RP11-34P13.8    NCBITaxon:9606   \n",
       "...                              ...           ...               ...   \n",
       "ENSG00000212907                 True       MT-ND4L    NCBITaxon:9606   \n",
       "ENSG00000198886                 True        MT-ND4    NCBITaxon:9606   \n",
       "ENSG00000198786                 True        MT-ND5    NCBITaxon:9606   \n",
       "ENSG00000198695                False        MT-ND6    NCBITaxon:9606   \n",
       "ENSG00000198727                 True        MT-CYB    NCBITaxon:9606   \n",
       "\n",
       "                feature_biotype feature_length  \n",
       "ENSG00000243485            gene           1021  \n",
       "ENSG00000237613            gene           1219  \n",
       "ENSG00000186092            gene           2618  \n",
       "ENSG00000238009            gene           3726  \n",
       "ENSG00000239945            gene           1319  \n",
       "...                         ...            ...  \n",
       "ENSG00000212907            gene            297  \n",
       "ENSG00000198886            gene           1378  \n",
       "ENSG00000198786            gene           1812  \n",
       "ENSG00000198695            gene            525  \n",
       "ENSG00000198727            gene           1141  \n",
       "\n",
       "[30933 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "czi_lupus_adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "retained_ensembl_ids = list(czi_lupus_adata.var.index)\n",
    "retained_gene_ids = list(czi_lupus_adata.var[\"feature_name\"])\n",
    "\n",
    "ensembl_id_out = path.join(out_metadata_dir, \"unfiltered_retained_ensembl_ids.txt\")\n",
    "gene_id_out = path.join(out_metadata_dir, \"unfiltered_retained_gene_ids.txt\")\n",
    "\n",
    "with open(ensembl_id_out, \"w\") as f:\n",
    "    f.write(\"\\n\".join(retained_ensembl_ids))\n",
    "\n",
    "with open(gene_id_out, \"w\") as f:\n",
    "    f.write(\"\\n\".join(retained_gene_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1263676, 30933)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "czi_lupus_adata.raw.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30268"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(czi_lupus_adata.raw.X[0].toarray() == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fitting indices: ind_cov: 100%|██████████| 261/261 [00:01<00:00, 251.11it/s]\n",
      "fitting indices: onek1k_cell_type: 100%|██████████| 16/16 [00:00<00:00, 25.01it/s]\n",
      "Aggregating Samples: 100%|██████████| 4176/4176 [00:32<00:00, 129.78it/s]\n"
     ]
    }
   ],
   "source": [
    "adpb = ADPBulk(czi_lupus_adata, [\"ind_cov\", \"onek1k_cell_type\"], use_raw=True, method=\"mean\")\n",
    "pseudobulk_matrix = adpb.fit_transform()\n",
    "\n",
    "pseudobulk_matrix = pseudobulk_matrix.T\n",
    "gene_names = czi_lupus_adata.var.feature_name\n",
    "pseudobulk_matrix.index = gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CD4_SOX4', 'CD4_NC', 'Plasma', 'Erythrocytes', 'CD8_ET', 'CD8_NC', 'Mono_C', 'CD8_S100B', 'DC', 'CD4_ET', 'NK_R', 'NK', 'Platelets', 'B_IN', 'B_MEM', 'Mono_NC']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B_IN',\n",
       " 'B_MEM',\n",
       " 'CD4_ET',\n",
       " 'CD4_NC',\n",
       " 'CD4_SOX4',\n",
       " 'CD8_ET',\n",
       " 'CD8_NC',\n",
       " 'CD8_S100B',\n",
       " 'DC',\n",
       " 'Mono_C',\n",
       " 'Mono_NC',\n",
       " 'NK',\n",
       " 'NK_R',\n",
       " 'Plasma']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_types = list(set(czi_lupus_adata.obs[\"onek1k_cell_type\"]))\n",
    "print(cell_types)\n",
    "reduced_cell_types = sorted(['Mono_NC', 'Plasma', 'CD8_ET', 'CD4_NC', 'Mono_C',\n",
    "'DC', 'CD8_NC', 'NK_R', 'B_MEM', 'CD4_ET', 'CD8_S100B', 'B_IN', 'NK', 'CD4_SOX4'])\n",
    "\n",
    "# reduced_cell_types = ['CD4_SOX4']\n",
    "\n",
    "reduced_cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_IN 261\n",
      "B_MEM 261\n",
      "CD4_ET 261\n",
      "CD4_NC 261\n",
      "CD4_SOX4 141\n",
      "CD8_ET 261\n",
      "CD8_NC 261\n",
      "CD8_S100B 260\n",
      "DC 259\n",
      "Mono_C 261\n",
      "Mono_NC 260\n",
      "NK 261\n",
      "NK_R 258\n",
      "Plasma 215\n"
     ]
    }
   ],
   "source": [
    "for cell_type in reduced_cell_types:\n",
    "    cell_type_cols = [col for col in pseudobulk_matrix if col.endswith(f\"{cell_type}\")]\n",
    "    cell_type_pseudobulk_matrix = pseudobulk_matrix[cell_type_cols]\n",
    "    print(cell_type, cell_type_pseudobulk_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sumagg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [16:21<00:00, 70.12s/it]\n",
      "100%|██████████| 14/14 [14:27<00:00, 61.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# normalize pseudobulk gene counts by cell type and store in sample-specific dictionaries\n",
    "# pseudobulk_matrix = pseudobulk_matrix.T\n",
    "\n",
    "# dics for tmm-transformed data\n",
    "gene_pseudobulk_dics = {}\n",
    "gene_pseudobulk_invnorm_dics = {}\n",
    "# for sample in donors:\n",
    "#     gene_pseudobulk_dics[sample] = {}\n",
    "\n",
    "gene_pseudobulk_residuals_dics = {}\n",
    "# for sample in donors:\n",
    "#     gene_pseudobulk_residuals_dics[sample] = {}\n",
    "# # note the dic below is for tmm-transformed data with the RESIDUALS inv-norm\n",
    "# # transformed\n",
    "gene_pseudobulk_residuals_invnorm_transformed_dics = {}\n",
    "# for ct in donors:\n",
    "#     gene_pseudobulk_residuals_invnorm_transformed_dics[sample] = {}\n",
    "\n",
    "for cell_type in tqdm(reduced_cell_types):\n",
    "    # define cells\n",
    "    cell_type_cols = [col for col in pseudobulk_matrix if col.endswith(f\"{cell_type}\")]\n",
    "    # subset to keep only cells of cell type\n",
    "    cell_type_pseudobulk_matrix = pseudobulk_matrix[cell_type_cols]\n",
    "    # create log+1 pseudobulk matrix (sumagg)\n",
    "    log_pseudobulk_matrix = np.log2(cell_type_pseudobulk_matrix + 1)\n",
    "    # inverse normal transform the log pseudobulk matrix\n",
    "    inv_norm_log_pseudobulk_matrix = qtl.norm.inverse_normal_transform(log_pseudobulk_matrix)\n",
    "    # get residual expression using RINT-log pseudobulk matrix\n",
    "    log_model_residuals = get_pca_linear_model_residuals(log_pseudobulk_matrix.T)\n",
    "    # RINT the model residuals\n",
    "    inv_norm_transformed_log_model_residuals = qtl.norm.inverse_normal_transform(log_model_residuals)\n",
    "    # define matrices to store log pseudobulk, RINT-log-pseudobulk, and RINT-log-residual-pseudobulk\n",
    "    df_columns = list(log_pseudobulk_matrix)\n",
    "    log_pseudobulk_matrix_df = lupus_create_ct_df(\n",
    "        log_pseudobulk_matrix,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    inv_norm_transformed_log_pseudobulk_matrix_df = lupus_create_ct_df(\n",
    "        inv_norm_log_pseudobulk_matrix,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    inv_norm_transformed_log_pseudobulk_model_residuals_df = lupus_create_ct_df(\n",
    "        inv_norm_transformed_log_model_residuals,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    # assign processed cell-type data to dictionaries\n",
    "    gene_pseudobulk_dics[cell_type] = log_pseudobulk_matrix_df\n",
    "    gene_pseudobulk_invnorm_dics[cell_type] = inv_norm_transformed_log_pseudobulk_matrix_df\n",
    "    gene_pseudobulk_residuals_invnorm_transformed_dics[cell_type] = inv_norm_transformed_log_pseudobulk_model_residuals_df\n",
    "\n",
    "\n",
    "out_cell_type_log_pseudobulk_dir = \"../data/lupus_cell_type_pseudobulk/sum_agg/log_pseudobulk_matrices\"\n",
    "makedirs(out_cell_type_log_pseudobulk_dir, exist_ok=True)\n",
    "\n",
    "out_cell_type_inv_norm_log_pseudobulk_dir = \"../data/lupus_cell_type_pseudobulk/sum_agg/invnorm_log_pseudobulk_matrices\"\n",
    "makedirs(out_cell_type_inv_norm_log_pseudobulk_dir, exist_ok=True)\n",
    "\n",
    "out_cell_type_inv_norm_log_pseudobulk_residuals_dir = \"../data/lupus_cell_type_pseudobulk/sum_agg/invnorm_regression_residuals\"\n",
    "makedirs(out_cell_type_inv_norm_log_pseudobulk_residuals_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for ct in tqdm(reduced_cell_types):\n",
    "    # process log tmm normalized\n",
    "    gene_pseudobulk_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_log_pseudobulk_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n",
    "\n",
    "    gene_pseudobulk_invnorm_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_inv_norm_log_pseudobulk_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n",
    "\n",
    "    gene_pseudobulk_residuals_invnorm_transformed_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_inv_norm_log_pseudobulk_residuals_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create log TMM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [11:17<00:00, 48.37s/it]\n",
      "100%|██████████| 14/14 [14:54<00:00, 63.89s/it]\n"
     ]
    }
   ],
   "source": [
    "# normalize pseudobulk gene counts by cell type and store in sample-specific dictionaries\n",
    "# pseudobulk_matrix = pseudobulk_matrix.T\n",
    "\n",
    "# dics for tmm-transformed data\n",
    "gene_pseudobulk_dics = {}\n",
    "gene_pseudobulk_invnorm_dics = {}\n",
    "# for sample in donors:\n",
    "#     gene_pseudobulk_dics[sample] = {}\n",
    "\n",
    "gene_pseudobulk_residuals_dics = {}\n",
    "# for sample in donors:\n",
    "#     gene_pseudobulk_residuals_dics[sample] = {}\n",
    "# # note the dic below is for tmm-transformed data with the RESIDUALS inv-norm\n",
    "# # transformed\n",
    "gene_pseudobulk_residuals_invnorm_transformed_dics = {}\n",
    "# for ct in donors:\n",
    "#     gene_pseudobulk_residuals_invnorm_transformed_dics[sample] = {}\n",
    "\n",
    "for cell_type in tqdm(reduced_cell_types):\n",
    "    # define cells\n",
    "    cell_type_cols = [col for col in pseudobulk_matrix if col.endswith(f\"{cell_type}\")]\n",
    "    # subset to keep only cells of cell type\n",
    "    cell_type_pseudobulk_matrix = pseudobulk_matrix[cell_type_cols]\n",
    "    # create TMM matrix\n",
    "    normalized_matrix = qtl.norm.edger_cpm(cell_type_pseudobulk_matrix, normalized_lib_sizes=True)\n",
    "    # create log+1 pseudobulk matrix (sumagg)\n",
    "    log_pseudobulk_matrix = np.log2(normalized_matrix + 1)\n",
    "    # inverse normal transform the log pseudobulk matrix\n",
    "    inv_norm_log_pseudobulk_matrix = qtl.norm.inverse_normal_transform(log_pseudobulk_matrix)\n",
    "    # get residual expression using RINT-log pseudobulk matrix\n",
    "    log_model_residuals = get_pca_linear_model_residuals(log_pseudobulk_matrix.T)\n",
    "    # RINT the model residuals\n",
    "    inv_norm_transformed_log_model_residuals = qtl.norm.inverse_normal_transform(log_model_residuals)\n",
    "    # define matrices to store log pseudobulk, RINT-log-pseudobulk, and RINT-log-residual-pseudobulk\n",
    "    df_columns = list(log_pseudobulk_matrix)\n",
    "    log_pseudobulk_matrix_df = lupus_create_ct_df(\n",
    "        log_pseudobulk_matrix,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    inv_norm_transformed_log_pseudobulk_matrix_df = lupus_create_ct_df(\n",
    "        inv_norm_log_pseudobulk_matrix,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    inv_norm_transformed_log_pseudobulk_model_residuals_df = lupus_create_ct_df(\n",
    "        inv_norm_transformed_log_model_residuals,\n",
    "        cell_type,\n",
    "        donors\n",
    "    )\n",
    "    # assign processed cell-type data to dictionaries\n",
    "    gene_pseudobulk_dics[cell_type] = log_pseudobulk_matrix_df\n",
    "    gene_pseudobulk_invnorm_dics[cell_type] = inv_norm_transformed_log_pseudobulk_matrix_df\n",
    "    gene_pseudobulk_residuals_invnorm_transformed_dics[cell_type] = inv_norm_transformed_log_pseudobulk_model_residuals_df\n",
    "\n",
    "\n",
    "out_cell_type_log_pseudobulk_dir = \"../data/lupus_cell_type_pseudobulk/log_tmm/log_pseudobulk_matrices\"\n",
    "makedirs(out_cell_type_log_pseudobulk_dir, exist_ok=True)\n",
    "\n",
    "out_cell_type_inv_norm_log_pseudobulk_dir = \"../data/lupus_cell_type_pseudobulk/log_tmm/invnorm_log_pseudobulk_matrices\"\n",
    "makedirs(out_cell_type_inv_norm_log_pseudobulk_dir, exist_ok=True)\n",
    "\n",
    "out_cell_type_inv_norm_log_pseudobulk_residuals_dir = \"../data/lupus_cell_type_pseudobulk/log_tmm/invnorm_regression_residuals\"\n",
    "makedirs(out_cell_type_inv_norm_log_pseudobulk_residuals_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for ct in tqdm(reduced_cell_types):\n",
    "    # process log tmm normalized\n",
    "    gene_pseudobulk_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_log_pseudobulk_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n",
    "\n",
    "    gene_pseudobulk_invnorm_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_inv_norm_log_pseudobulk_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n",
    "\n",
    "    gene_pseudobulk_residuals_invnorm_transformed_dics[ct].to_csv(\n",
    "        path.join(out_cell_type_inv_norm_log_pseudobulk_residuals_dir, f\"{ct}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=True,\n",
    "        index_label=\"gene_id\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
